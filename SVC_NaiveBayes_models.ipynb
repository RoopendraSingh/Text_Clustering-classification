{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from stop_words import get_stop_words\n",
    "import calendar\n",
    "import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "import eli5\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1301, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data=pd.read_csv(\"Property Datasets/Upsampled_train_data/Train_Up_data.csv\")\n",
    "test_data1=pd.read_csv(\"Property Datasets/Simple_Data/Test_data_property.csv\")\n",
    "val_data=pd.read_csv(\"Property Datasets/Simple_Data/Val_data_property.csv\")\n",
    "test_data=pd.concat([test_data1,val_data],axis=0)\n",
    "test_data.reset_index(drop=True,inplace=True)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data[\"Label\"].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train_data.Text\n",
    "y=train_data['Label']\n",
    "x1=test_data.Text\n",
    "y1=test_data['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Preprocessing Data ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(x):\n",
    "    import datetime\n",
    "    # Month name from number\n",
    "    month_num = 1\n",
    "    month_abre = datetime.date(2015, month_num, 1).strftime('%b')\n",
    "    month_name = datetime.date(2015, month_num, 1).strftime('%B')\n",
    "\n",
    "    # Print list of all months from calendar\n",
    "    month_abr=[]\n",
    "    month=[]\n",
    "    for month_val in range(1, 13):\n",
    "        month_abr.append(calendar.month_abbr[month_val])\n",
    "        month.append(calendar.month_name[month_val])\n",
    "    month_abrev=[word.lower() for word in month_abr ] \n",
    "    months=[word.lower() for word in month ]\n",
    "    months.extend(month_abrev)\n",
    "\n",
    "    stop_words = (list(\n",
    "        set(get_stop_words('en'))\n",
    "        |set(months)\n",
    "    ))\n",
    "    stop_words.extend([\"claim\",'id','dopa',\"arise\",\"claimant\",\"allegations\",\"auto\",\"ploicy\",\"care\",\"work\",\"potential\",\n",
    "                        \"service\",\"allegdly\",\"allege\",\"clmt\",\"insd\",'insure','incident','covid-19','covid','complaint',\n",
    "                      'ovid','state','district','plaintiff','instal','due','demand','locate',\n",
    "                        'cause','client','customer','date','understand','app'])\n",
    "\n",
    "\n",
    "    REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "    def preprocess_reviews(reviews):\n",
    "        reviews= [line.lower() for line in reviews]\n",
    "        reviews = [str (item) for item in reviews]\n",
    "        reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "        reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "        return reviews\n",
    "    reviews_train_clean = preprocess_reviews(x)\n",
    "    \n",
    "    def get_lemmatized_text(corpus):\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        return [' '.join([lemmatizer.lemmatize(word,'v') for word in review.split()]) for review in corpus]\n",
    "    reviews_train_clean = get_lemmatized_text(reviews_train_clean)  \n",
    "        \n",
    "    only_alpha=[]\n",
    "    for i in reviews_train_clean:\n",
    "        s=re.sub(\"[^A-Za-z]\",\" \",str(i))\n",
    "        s=re.sub(\"  +\",\" \",s)\n",
    "        s = re.sub(r\"\\bprop\\b\",\"property\",s)\n",
    "        s = re.sub(r\"\\bcvg\\b\",\"coverage\",s)\n",
    "        s = re.sub(r'\\d',' ', s)\n",
    "        only_alpha.append(s)\n",
    "        \n",
    "    def remove_stop_words(corpus):\n",
    "        removed_stop_words = []\n",
    "        for review in corpus:\n",
    "            removed_stop_words.append(\n",
    "                ' '.join([word for word in review.split()\n",
    "                          if word not in stop_words])\n",
    "            )\n",
    "        return removed_stop_words\n",
    "    after_sw = remove_stop_words(only_alpha)\n",
    "    return(after_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1301 15202\n",
      "1301 15202\n"
     ]
    }
   ],
   "source": [
    "x_train=Preprocessing(x)\n",
    "x_test=Preprocessing(x1)\n",
    "print(len(x_test),len(x_train))\n",
    "y_train=np.array(y)\n",
    "y_test=np.array(y1)\n",
    "print(len(y_test),len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vec(a,b):\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    count_vectorizer.fit(x_train)\n",
    "    a = count_vectorizer.transform(a).toarray()\n",
    "    b = count_vectorizer.transform(b).toarray()\n",
    "    return a,b\n",
    "\n",
    "def ngram_count_vec(a,b):\n",
    "    count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "    count_vectorizer.fit(x_train)\n",
    "    a = count_vectorizer.transform(a).toarray()\n",
    "    b = count_vectorizer.transform(b).toarray()\n",
    "    return a,b\n",
    "\n",
    "def tfidf_vec(a,b):\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_vectorizer.fit(x_train)\n",
    "    a = tfidf_vectorizer.transform(a).toarray()\n",
    "    b = tfidf_vectorizer.transform(b).toarray()\n",
    "    return a,b\n",
    "\n",
    "def ngram_tfidf_vec(a,b):\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "    tfidf_vectorizer.fit(x_train)\n",
    "    a = tfidf_vectorizer.transform(a).toarray()\n",
    "    b = tfidf_vectorizer.transform(b).toarray()\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Naive_Bayes ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes-tfidf_vec 78.55495772482706\n",
      "NaiveBayes-ngram_tfidf_vec 78.63182167563413\n",
      "NaiveBayes-count_vec 78.09377401998464\n",
      "NaiveBayes-ngram_count_vec 76.94081475787856\n"
     ]
    }
   ],
   "source": [
    "V = [tfidf_vec , ngram_tfidf_vec, count_vec , ngram_count_vec]\n",
    "B = ['tfidf_vec' , 'ngram_tfidf_vec', 'count_vec' , 'ngram_count_vec']\n",
    "\n",
    "num_of_funcs = len(V)\n",
    "vector = []\n",
    "accuracy = []\n",
    "f1=[]\n",
    "recall=[]\n",
    "precision=[]\n",
    "f1_all=[]\n",
    "recall_all=[]\n",
    "precision_all=[]\n",
    "for i,j in zip(range(num_of_funcs),B):\n",
    "    xtrain_vec, xtest_vec = V[i % num_of_funcs](x_train, x_test)\n",
    "    model = MultinomialNB().fit(xtrain_vec, y_train)\n",
    "    y_pred = model.predict(xtest_vec)\n",
    "    acc_score=accuracy_score(y_test,y_pred)\n",
    "    f1.append(f1_score(y_test,y_pred,average='macro'))\n",
    "    recall.append(recall_score(y_test,y_pred,average='macro'))\n",
    "    precision.append(precision_score(y_test,y_pred,average='macro'))\n",
    "    accuracy.append(acc_score)\n",
    "    f1_all.append(f1_score(y_test,y_pred,average=None))\n",
    "    recall_all.append(recall_score(y_test,y_pred,average=None))\n",
    "    precision_all.append(precision_score(y_test,y_pred,average=None))\n",
    "    vector.append(j)\n",
    "    print(\"NaiveBayes-\"+j,acc_score*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive_Bayes</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_vec</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.786318</td>\n",
       "      <td>0.780938</td>\n",
       "      <td>0.769408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ngram_tfidf_vec</td>\n",
       "      <td>0.696889</td>\n",
       "      <td>0.703816</td>\n",
       "      <td>0.690285</td>\n",
       "      <td>0.668454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>count_vec</td>\n",
       "      <td>0.663773</td>\n",
       "      <td>0.671517</td>\n",
       "      <td>0.669312</td>\n",
       "      <td>0.647722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ngram_count_vec</td>\n",
       "      <td>0.757184</td>\n",
       "      <td>0.762428</td>\n",
       "      <td>0.738430</td>\n",
       "      <td>0.717796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Naive_Bayes  Accuracy  F1-score  Precision    Recall\n",
       "0        tfidf_vec  0.785550  0.786318   0.780938  0.769408\n",
       "1  ngram_tfidf_vec  0.696889  0.703816   0.690285  0.668454\n",
       "2        count_vec  0.663773  0.671517   0.669312  0.647722\n",
       "3  ngram_count_vec  0.757184  0.762428   0.738430  0.717796"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(vector)\n",
    "df2 = pd.DataFrame([accuracy,f1,precision,recall])\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True, sort=False, axis =1)\n",
    "df.columns = ['Naive_Bayes', 'Accuracy',\"F1-score\",\"Precision\",\"Recall\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.771605</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.640152</td>\n",
       "      <td>0.946565</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.853801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.643939</td>\n",
       "      <td>0.938931</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.871345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.787037</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.954198</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.771930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.771605</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.651515</td>\n",
       "      <td>0.950382</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.783626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.863636  0.956522  0.771605  0.529412  0.431818  0.941176  0.640152   \n",
       "1  0.818182  1.000000  0.765432  0.558824  0.454545  0.941176  0.643939   \n",
       "2  0.795455  0.956522  0.787037  0.470588  0.409091  0.882353  0.670455   \n",
       "3  0.772727  0.956522  0.771605  0.500000  0.386364  0.901961  0.651515   \n",
       "\n",
       "         7         8         9         10  \n",
       "0  0.946565  0.578947  0.815385  0.853801  \n",
       "1  0.938931  0.578947  0.815385  0.871345  \n",
       "2  0.954198  0.578947  0.846154  0.771930  \n",
       "3  0.950382  0.421053  0.800000  0.783626  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(recall_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SVM-SVC #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-tfidf_vec 84.0891621829362\n",
      "SVM-ngram_tfidf_vec 85.62644119907763\n",
      "SVM-count_vec 84.6272098385857\n",
      "SVM-ngram_count_vec 86.01076095311299\n"
     ]
    }
   ],
   "source": [
    "V = [tfidf_vec , ngram_tfidf_vec, count_vec , ngram_count_vec]\n",
    "B = ['tfidf_vec' , 'ngram_tfidf_vec', 'count_vec' , 'ngram_count_vec']\n",
    "\n",
    "num_of_funcs = len(V)\n",
    "vector = []\n",
    "accuracy = []\n",
    "f1=[]\n",
    "recall=[]\n",
    "precision=[]\n",
    "f1_all=[]\n",
    "recall_all=[]\n",
    "precision_all=[]\n",
    "for i,j in zip(range(num_of_funcs),B):\n",
    "    xtrain_vec, xtest_vec = V[i % num_of_funcs](x_train, x_test)\n",
    "    svm = LinearSVC(class_weight='balanced', verbose=False, max_iter=10000, tol=1e-4, C=0.1)\n",
    "    model = svm.fit(xtrain_vec, y_train)\n",
    "    y_pred = model.predict(xtest_vec)\n",
    "    acc_score=accuracy_score(y_test,y_pred)\n",
    "    f1.append(f1_score(y_test,y_pred,average='macro'))\n",
    "    recall.append(recall_score(y_test,y_pred,average='macro'))\n",
    "    precision.append(precision_score(y_test,y_pred,average='macro'))\n",
    "    accuracy.append(acc_score)\n",
    "    f1_all.append(f1_score(y_test,y_pred,average=None))\n",
    "    recall_all.append(recall_score(y_test,y_pred,average=None))\n",
    "    precision_all.append(precision_score(y_test,y_pred,average=None))\n",
    "    vector.append(j)\n",
    "    print(\"SVM-\"+j,acc_score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(vector)\n",
    "df2 = pd.DataFrame([accuracy,f1,precision,recall])\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True, sort=False, axis =1)\n",
    "df.columns = ['Naive_Bayes', 'Accuracy',\"F1-score\",\"Precision\",\"Recall\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.799383</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.961832</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.923977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.817901</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.961832</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.961832</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.941520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.961832</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.818182  0.956522  0.799383  0.529412  0.522727  0.941176  0.791667   \n",
       "1  0.818182  0.956522  0.817901  0.558824  0.545455  0.960784  0.818182   \n",
       "2  0.795455  0.869565  0.824074  0.529412  0.454545  0.901961  0.818182   \n",
       "3  0.727273  0.869565  0.851852  0.441176  0.545455  0.921569  0.863636   \n",
       "\n",
       "         7         8         9         10  \n",
       "0  0.961832  0.631579  0.876923  0.923977  \n",
       "1  0.961832  0.578947  0.892308  0.947368  \n",
       "2  0.961832  0.631579  0.830769  0.941520  \n",
       "3  0.961832  0.578947  0.800000  0.947368  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(recall_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
